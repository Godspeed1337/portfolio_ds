{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CatBoost</a></span><ul class=\"toc-item\"><li><span><a href=\"#аргумент-text_features\" data-toc-modified-id=\"аргумент-text_features-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>аргумент text_features</a></span></li><li><span><a href=\"#Pipeline-с-tf-idf\" data-toc-modified-id=\"Pipeline-с-tf-idf-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Pipeline с tf-idf</a></span></li></ul></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#KNeighborsClassifier\" data-toc-modified-id=\"KNeighborsClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>KNeighborsClassifier</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>LogisticRegression</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span><ul class=\"toc-item\"><li><span><a href=\"#Данные:\" data-toc-modified-id=\"Данные:-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Данные:</a></span></li><li><span><a href=\"#Модели:\" data-toc-modified-id=\"Модели:-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Модели:</a></span></li></ul></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация токсичных комментариев для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель проекта — обучить модель для автоматического определения токсичных пользовательских комментариев на платформе интернет-магазина «Викишоп». Это поможет направлять оскорбительные правки на модерацию.\n",
    "\n",
    "Источник данных: размеченный набор toxic_comments.csv с текстами комментариев и бинарной меткой токсичности.\n",
    "\n",
    "Основные этапы:\n",
    "- Предобработка текста и токенизация.\n",
    "- Обучение и сравнение нескольких моделей машинного обучения.\n",
    "- Оценка качества моделей по метрике F1 (целевой порог — не ниже 0.75).\n",
    "\n",
    "Проект демонстрирует навыки текстовой предобработки, работы с моделями классификации и оценки качества моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -q catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.* in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (67.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 217.9 kB/s eta 0:00:59\n",
      "     --------------------------------------- 0.0/12.8 MB 326.8 kB/s eta 0:00:40\n",
      "     --------------------------------------- 0.1/12.8 MB 655.4 kB/s eta 0:00:20\n",
      "      --------------------------------------- 0.2/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.3/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.3 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.1/12.8 MB 4.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.0/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.0/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.0/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.4/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.9/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.4/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 8.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.6/12.8 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 11.1/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.7/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.2/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.20.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:34:23.265427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-16 17:34:23.265787: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-16 17:34:29.604214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-16 17:34:29.604560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2023-04-16 17:34:29.604893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2023-04-16 17:34:29.605220: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2023-04-16 17:34:29.605538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2023-04-16 17:34:29.605861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2023-04-16 17:34:29.606182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2023-04-16 17:34:29.606499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2023-04-16 17:34:29.606515: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.*\n",
    "!pip install spacy\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxic_comments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxic_comments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://code.s3.yandex.net/datasets/toxic_comments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Загрузка данных, к сожалению, по политиике Яндекса, показать не могу\n",
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data: pd.DataFrame):\n",
    "    display(data.head())\n",
    "    print('\\n INFO\\n')\n",
    "    data.info()\n",
    "    print('\\n Дупликаты общие \\n')\n",
    "    display(data[data.duplicated()])\n",
    "    print('\\n Пропущенные данные в % \\n')\n",
    "    display(data.isna().mean()*100)\n",
    "    display(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INFO\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "\n",
      " Дупликаты общие \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, text, toxic]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Пропущенные данные в % \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0.0\n",
       "text          0.0\n",
       "toxic         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>159292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>List of present day countries that were part o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0                                               text  \\\n",
       "count   159292.000000                                             159292   \n",
       "unique            NaN                                             159292   \n",
       "top               NaN  List of present day countries that were part o...   \n",
       "freq              NaN                                                  1   \n",
       "mean     79725.697242                                                NaN   \n",
       "std      46028.837471                                                NaN   \n",
       "min          0.000000                                                NaN   \n",
       "25%      39872.750000                                                NaN   \n",
       "50%      79721.500000                                                NaN   \n",
       "75%     119573.250000                                                NaN   \n",
       "max     159450.000000                                                NaN   \n",
       "\n",
       "                toxic  \n",
       "count   159292.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.101612  \n",
       "std          0.302139  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return \" \".join((re.sub(r'[^a-zA-Z ]', ' ', text)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 27s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['clear_text'] = data.text.apply(clear_text)\n",
    "data['lemma_text'] = data.clear_text.apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['lemma_text']\n",
    "Y = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, targets_train, targets_test = train_test_split(X, Y,\n",
    "                                                                              test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_Cat = CatBoostClassifier(random_state=RANDOM_STATE, allow_writing_files=False, verbose=False, auto_class_weights='Balanced')\n",
    "\n",
    "\n",
    "param_grid_Cat = {'catboost__learning_rate': [0.01, 0.05, 0.1, 0.3]}\n",
    "#'depth': range(3, 10),\n",
    "#'l2_leaf_reg': [1, 3, 5, 7, 9],}\n",
    "tfidf_cat_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('catboost', model_Cat)\n",
    "])\n",
    "\n",
    "gs_Cat = GridSearchCV(\n",
    "    tfidf_cat_pipe,\n",
    "    param_grid=param_grid_Cat,\n",
    "    scoring='f1',\n",
    "    n_jobs=5,\n",
    "    cv=5,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "gs_Cat.fit(features_train, targets_train)\n",
    "\n",
    "gs_Cat_best_score = gs_Cat.best_score_\n",
    "gs_Cat_best_params = gs_Cat.best_params_\n",
    "\n",
    "# лучшее значение f1 на кросс-валидации\n",
    "print(f'best_score: {gs_Cat_best_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_Cat_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Долго учится, я устал ждать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### аргумент text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score [0.72796329 0.72073499 0.71446822 0.72850024 0.73560252]\n"
     ]
    }
   ],
   "source": [
    "features_train_df = pd.DataFrame({'lemma_text':features_train.values}, index=features_train.index)\n",
    "model_Cat = CatBoostClassifier(random_state=RANDOM_STATE, allow_writing_files=False, verbose=False, auto_class_weights='Balanced', text_features=['lemma_text',])\n",
    "print('CV score', cross_val_score(\n",
    "    model_Cat,\n",
    "    features_train_df,\n",
    "    targets_train,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725453852\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([0.72796329, 0.72073499, 0.71446822, 0.72850024, 0.73560252]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline с tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score [0.76008418 0.7578388  0.74862905 0.76533287 0.76337778]\n",
      "mean 0.7590525336124555\n"
     ]
    }
   ],
   "source": [
    "model_Cat = CatBoostClassifier(random_state=RANDOM_STATE, allow_writing_files=False, verbose=False, auto_class_weights='Balanced')\n",
    "tfidf_cat_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('catboost', model_Cat)\n",
    "])\n",
    "cv_score = cross_val_score(\n",
    "    tfidf_cat_pipe,\n",
    "    features_train,\n",
    "    targets_train,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "print('CV score', cv_score)\n",
    "print('mean', np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score [0.66082603 0.64920675 0.63640974 0.65449087 0.64448959]\n",
      "mean 0.6490845949107026\n",
      "CPU times: total: 703 ms\n",
      "Wall time: 13min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_forest = RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\")\n",
    "tfidf_forest_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('forest', model_forest)\n",
    "])\n",
    "cv_score = cross_val_score(\n",
    "    tfidf_forest_pipe,\n",
    "    features_train,\n",
    "    targets_train,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "print('CV score', cv_score)\n",
    "print('mean', np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score [0.32354778 0.28598073 0.29800499 0.30443038 0.3037575 ]\n",
      "mean 0.30314427530204646\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_knn = KNeighborsClassifier()\n",
    "tfidf_knn_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('knn', model_knn)\n",
    "])\n",
    "cv_score = cross_val_score(\n",
    "    tfidf_knn_pipe,\n",
    "    features_train,\n",
    "    targets_train,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    "    )\n",
    "print('CV score', cv_score)\n",
    "print('mean', np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрее всего  надо было делать балансировку через downsample или upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.74855796        nan        nan        nan 0.66226117\n",
      " 0.75050772 0.75052534 0.75055064        nan 0.75057697 0.7515628\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72668521        nan 0.57624604        nan 0.72523045 0.73466493]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.7515628038076635\n",
      "best_params: {'log__penalty': 'l2', 'log__solver': 'saga'}\n",
      "CPU times: total: 43 s\n",
      "Wall time: 8min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_log = LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "\n",
    "\n",
    "param_grid_log = {'log__solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "                 'log__penalty': ['l1', 'l2', 'elasticnet', 'none']}\n",
    "\n",
    "tfidf_log_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('log', model_log)\n",
    "])\n",
    "\n",
    "gs_log = GridSearchCV(\n",
    "    tfidf_log_pipe,\n",
    "    param_grid=param_grid_log,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "gs_log.fit(features_train, targets_train)\n",
    "\n",
    "gs_log_best_score = gs_log.best_score_\n",
    "gs_log_best_params = gs_log.best_params_\n",
    "\n",
    "# лучшее значение f1 на кросс-валидации\n",
    "print(f'best_score: {gs_log_best_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_log_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost показал лучшие результаты по метрике f1, используем его на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score на тестовой выборке: 0.7613540197461213\n",
      "CPU times: total: 1h 14min 34s\n",
      "Wall time: 10min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_Cat = CatBoostClassifier(random_state=RANDOM_STATE, allow_writing_files=False, verbose=False, auto_class_weights='Balanced')\n",
    "tfidf_cat_pipe = Pipeline([\n",
    "    ('tvec', vectorizer),\n",
    "    ('catboost', model_Cat)\n",
    "])\n",
    "tfidf_cat_pipe.fit(features_train, targets_train)\n",
    "predictions = tfidf_cat_pipe.predict(features_test)\n",
    "print('f1 score на тестовой выборке:', f1_score(targets_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные:\n",
    "Была произведена **лемматизация** текста.  \n",
    "Признаки закодированы с помощью **Tf-Idf**.  \n",
    "### Модели:\n",
    "Проанализированы 4 модели.  \n",
    "На кросс валидации лучшим себя показал CatBoost.  \n",
    "Его метрика F1 score на тестовой выборке **0.7614**"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 65078,
    "start_time": "2023-04-15T14:47:30.688Z"
   },
   {
    "duration": 8747,
    "start_time": "2023-04-15T14:48:35.769Z"
   },
   {
    "duration": 2848,
    "start_time": "2023-04-15T14:48:44.518Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-15T14:48:47.378Z"
   },
   {
    "duration": 797,
    "start_time": "2023-04-15T14:48:47.399Z"
   },
   {
    "duration": 1403,
    "start_time": "2023-04-15T14:48:48.199Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-15T14:48:49.604Z"
   },
   {
    "duration": 161,
    "start_time": "2023-04-15T14:48:49.610Z"
   },
   {
    "duration": 18884,
    "start_time": "2023-04-15T14:56:50.712Z"
   },
   {
    "duration": 7067,
    "start_time": "2023-04-15T14:57:09.598Z"
   },
   {
    "duration": 2960,
    "start_time": "2023-04-15T14:57:16.667Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-15T14:57:19.629Z"
   },
   {
    "duration": 848,
    "start_time": "2023-04-15T14:57:19.643Z"
   },
   {
    "duration": 3367,
    "start_time": "2023-04-15T14:58:06.263Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-15T14:58:09.632Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-15T14:58:29.187Z"
   },
   {
    "duration": 69,
    "start_time": "2023-04-15T14:58:29.812Z"
   },
   {
    "duration": 269,
    "start_time": "2023-04-15T15:00:07.113Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-15T15:00:23.571Z"
   },
   {
    "duration": 148,
    "start_time": "2023-04-15T15:00:32.481Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-15T15:00:40.577Z"
   },
   {
    "duration": 7516,
    "start_time": "2023-04-15T15:00:47.308Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
